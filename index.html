<!DOCTYPE html>
<html>
<head>
	<section id="header">
		<header>
		<h1>How does music evolve over time?</h1>
		<p> Justin Duong - Jared Leong - Kevin Mouayang</p>
		</header>
		<p>
			The following visualization was created using the
			<a href="https://www.kaggle.com/theoverman/the-spotify-hit-predictor-dataset">
				Spotify Hit Predictor Dataset from Kaggle</a>.
		</p>
		<p>
			All of the songs used to produce the visualization were songs that were
			featured at least once on Billboards Hot 100 list. Hence, making the song a "hit"
		</p>
		<p>
			The audio features (valence, energy etc.) come from the
			<a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/">
				 Spotify Web API</a>
		</p>
	</section>
	<p>

	</p>
	<footer>
		<a href="#banner" class="button style2 scrolly">Audio feature definitions</a>
	</footer>
	
	<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
	<title>Spotify Data Radar Chart</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	<!-- Google fonts -->
	<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
	<link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>

	<!-- D3.js -->
	<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.min.js" charset="utf-8"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/d3-legend/1.3.0/d3-legend.js" charset="utf-8"></script>
	
	<style>
		body {
			font-family: 'Open Sans', sans-serif;
			font-size: 15px;
			font-weight: 500;
			fill: #ffffff;
			text-align: center;
			<!--text-shadow: 0 1px 0 #fff, 1px 0 0 #fff, -1px 0 0 #fff, 0 -1px 0 #fff;-->
			cursor: default;
		}

		.tooltip {
			fill: #242424;
			font-size: 20px;
			font-weight: 600;
		}
	</style>
</head>
<body>
	<div id="radar"></div>
<div class="radarChart"></div>
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.poptrox.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>
<script src="radarChart.js"></script>
<script>
	//////////////////////////////////////////////////////////////
	//////////////////////// Set-Up //////////////////////////////
	//////////////////////////////////////////////////////////////
	
	var margin = {top: 100, right: 350, bottom: 100, left: 350},
			legendPosition = {x: 0, y: 100},
			width = Math.min(700, window.innerWidth - 10)-200,
			//width = Math.min(1000, window.innerWidth) - margin.left - margin.right,
			height = Math.min(width, window.innerHeight-200);

	//////////////////////////////////////////////////////////////
	//////////////////// Draw the Chart //////////////////////////
	//////////////////////////////////////////////////////////////

	var color = d3.scale.ordinal()
			.range(["#1DB954","#CC333F","#00A0B0","#b000a0","#3CF3CC","#f5aa42"]);

	var radarChartOptions = {
		w: width,
		h: height,
		margin: margin,
		legendPosition: legendPosition,
		maxValue: 0.5,
		wrapWidth: 60,
		levels: 5,
		roundStrokes: true,
		color: color,
		axisName:"categories",
		areaName:"year",
		value: "value"
	};

	//Load the data and Call function to draw the Radar chart
	d3.json("spotifyHits.json", function(error, data){
		RadarChart(".radarChart", data, radarChartOptions);
	});
	</script>
	
	<!-- Load d3.js -->
	<script src="https://d3js.org/d3.v4.js"></script>

	<!-- Function for radial charts -->
	<script src="https://cdn.jsdelivr.net/gh/holtzy/D3-graph-gallery@master/LIB/d3-scale-radial.js"></script>

	
	<!-- Create a div where the graph will take place -->
	<div id="my_dataviz"></div>
	<div class="dataviz"></div>
	<script>
		
	// set the dimensions and margins of the graph
	var margin = {top: 300, right: 500, bottom: 300, left: 530},
	    width = 810, //- margin.left - margin.right,
	    height = 800; //- margin.top - margin.bottom;

	// append the svg object to the body of the page
	var svg = d3.select("#my_dataviz")
	  .append("svg")
	    .attr("width", width + margin.left + margin.right)
	    .attr("height", height + margin.top + margin.bottom)
	  .append("g")
	    .attr("transform",
		  "translate(" + margin.left + "," + margin.top + ")");

	//Read the data
	d3.csv("spotifyPlaylistFixedExtreme.csv", function(data) {

	  // Add X axis
	  var x = d3.scaleLinear()
	    .domain([1960, 2010])
	    .range([ 0, width ]);
	  svg.append("g")
	    .attr("transform", "translate(0," + height + ")")
	    .call(d3.axisBottom(x));

	  // Add Y axis
	  var y = d3.scaleLinear()
	    .domain([0, 30])
	    .range([ height, 0]);
	  svg.append("g")
	    .call(d3.axisLeft(y));

	// Add a clipPath: everything out of this area won't be drawn.
	  var clip = svg.append("defs").append("svg:clipPath")
	      .attr("id", "clip")
	      .append("svg:rect")
	      .attr("width", width )
	      .attr("height", height )
	      .attr("x", 0)
	      .attr("y", 0);

	  // Create the scatter variable: where both the circles and the brush take place
	  var scatter = svg.append('g')
	    .attr("clip-path", "url(#clip)")
		
		// Add circles
	  scatter
	    .selectAll("circle")
	    .data(data)
	    .enter()
	    .append("circle")
	      .attr("cx", function (d) { return x(d.year); } )
	      .attr("cy", function (d) { return y(d.duration); } )
	      .attr("r", 8)
	      .style("fill", "#61a3a9")
	      .style("opacity", 0.5)

	  // Set the zoom and Pan features: how much you can zoom, on which part, and what to do when there is a zoom
	  var zoom = d3.zoom()
	      .scaleExtent([.5, 20])  // This control how much you can unzoom (x0.5) and zoom (x20)
	      .extent([[0, 0], [width, height]])
	      .on("zoom", updateChart);
		
	  // Add a tooltip div. Here I define the general feature of the tooltip: stuff that do not depend on the data point.
	  // Its opacity is set to 0: we don't see it by default.
	  var tooltip = d3.select("#my_dataviz")
	    .append("div")
	    .style("opacity", 0)
	    .attr("class", "tooltip")
	    .style("background-color", "white")
	    .style("border", "solid")
	    .style("border-width", "1px")
	    .style("border-radius", "5px")
	    .style("padding", "10px")

	  
	  // A function that change this tooltip when the user hover a point.
	  // Its opacity is set to 1: we can now see it. Plus it set the text and position of tooltip depending on the datapoint (d)
	  var mouseover = function(d) {
	    tooltip
	      .style("opacity", 1)
	  }

	  var mousemove = function(d) {
	    tooltip
	      .html("The exact value of<br>the duration is: " + d.duration + "<br/>The name of the song is: " + d.track)
	      .style("left", (d3.mouse(this)[0]+90) + "px") // It is important to put the +90: other wise the tooltip is exactly where the point is an it creates a weird effect
	      .style("top", (d3.mouse(this)[1]) + "px")
	  }

	  // A function that change this tooltip when the leaves a point: just need to set opacity to 0 again
	  var mouseleave = function(d) {
	    tooltip
	      .transition()
	      .duration(200)
	      .style("opacity", 0)
	  }

	  // Add dots
	  svg.append('g')
	    .selectAll("dot")
	    .data(data) // the .filter part is just to keep a few dots on the chart, not all of them
	    .enter()
	    .append("circle")
	      .attr("cx", function (d) { return x(d.year); } )
	      .attr("cy", function (d) { return y(d.duration); } )
	      .attr("r", 7)
	      .style("fill", "#69b3a2")
	      .style("opacity", 0.3)
	      .style("stroke", "white")
	    .on("mouseover", mouseover )
	    .on("mousemove", mousemove )
	    .on("mouseleave", mouseleave )
		
	svg.append("rect")
	      .attr("width", width)
	      .attr("height", height)
	      .style("fill", "none")
	      .style("pointer-events", "all")
	      .attr('transform', 'translate(' + margin.left + ',' + margin.top + ')')
	      .call(zoom);
		
		// A function that updates the chart when the user zoom and thus new boundaries are available
	  function updateChart() {

	    // recover the new scale
	    var newX = d3.event.transform.rescaleX(x);
	    var newY = d3.event.transform.rescaleY(y);

	    // update axes with these new boundaries
	    xAxis.call(d3.axisBottom(newX))
	    yAxis.call(d3.axisLeft(newY))

	    // update circle position
	    scatter
	      .selectAll("circle")
	      .attr('cx', function(d) {return newX(d.year)})
	      .attr('cy', function(d) {return newY(d.duration)});
	  }
	})
	</script>
	
	
	<section id="banner">
	<p>
		<i>Danceability</i> - Danceability describes how suitable
		a track is for dancing based on a combination of
		musical elements including tempo, rhythm stability,
		beat strength, and overall regularity. A value of 0.0
		is least danceable and 1.0 is most danceable.
	</p>
	<p>
		<i>Valence</i> - A measure from 0.0 to 1.0 describing the
		musical positiveness conveyed by a track. Tracks with
		high valence sound more positive (e.g. happy, cheerful, euphoric),
		while tracks with low valence sound more negative
		(e.g. sad, depressed, angry).
	</p>
	<p>
		<i>Energy</i> - Energy is a measure from 0.0 to 1.0 and
		represents a perceptual measure of intensity and activity.
		Typically, energetic tracks feel fast, loud, and noisy. For
		example, death metal has high energy, while a Bach prelude
		scores low on the scale. Perceptual features contributing to
		this attribute include dynamic range, perceived loudness, timbre,
		onset rate, and general entropy.
	</p>
	<p>
		<i>Liveness</i> - Detects the presence of an audience in the recording.
		Higher liveness values represent an increased probability that
		the track was performed live. A value above 0.8 provides strong
		likelihood that the track is live.
	</p>
	<p>
		<i>Instrumentalness</i> - Predicts whether a track contains no vocals.
		“Ooh” and “aah” sounds are treated as instrumental in this context.
		Rap or spoken word tracks are clearly “vocal”. The closer the
		instrumentalness value is to 1.0, the greater likelihood the track
		contains no vocal content. Values above 0.5 are intended to represent
		instrumental tracks, but confidence is higher as the value approaches 1.0.
	</p>
	<p>
		<i>Acousticness</i> - A confidence measure from 0.0 to 1.0 of whether
		the track is acoustic. 1.0 represents high confidence the track
		is acoustic.
	</p>
	<p>
		<i>Speechiness</i> - Speechiness detects the presence of spoken words
		in a track. The more exclusively speech-like the recording
		(e.g. talk show, audio book, poetry), the closer to 1.0 the attribute
		value. Values above 0.66 describe tracks that are probably made
		entirely of spoken words. Values between 0.33 and 0.66 describe
		tracks that may contain both music and speech, either in sections
		or layered, including such cases as rap music. Values below 0.33
		most likely represent music and other non-speech-like tracks.
	</p>
	</section>

	<div id="writeup"></div>
<article style="background-color: #35b88f;" class="container box style3">
	<header>
		<h2>Write-Up</h2>
		<p style="font-style: italic;">1) A rationale for your design decisions.
			How did you choose your particular visual encodings and
			interaction techniques? What alternatives did you consider
			and how did you arrive at your ultimate choices?</p>
		<p>Our question was based around if the
			traits of “hit” songs changed over time so we
			wanted a visualization that could emphasize the
			differences in the values of these traits
			throughout difference decades of music. One
			of the alternatives we considered was a heatmap,
			but we felt that a heatmap wasn’t interactive
			enough and that something like a radar chart was
			more applicable to our question and dataset.</p>
		<p style="font-style: italic;">2) An overview of
			your development process. Describe how the work
			was split among the team members. Include a
			commentary on the development process, including
			answers to the following questions: Roughly how
			much time did you spend developing your application
			(in people-hours)? What aspects took the most time?</p>
		<p>We started out by brainstorming ideas for what kind
			of dataset we could use based on our own interests
			(music?). After finding a dataset, we familiarized
			ourselves with possible visualizations we could use
			and looked at their implementations using D3. Once we
			settled on the radar chart, we split the work between
			implementing the visualization and putting things like
			text on the page, debugging, and transforming the dataset
			using Trifacta. The most time-consuming part was figuring
			out which dataset and visualization to use. We spent
			around 30 hours in total to complete the assignment from
			start to finish.</p>
	</header>
</article>
	<section id="footer">

	</section>
</body>
</html>
